#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”¨äºç”ŸæˆCå­—æ¯å•è¯å­¦ä¹ èµ„æ–™çš„è„šæœ¬
æ ¹æ®å­¦ä½è‹±è¯­è¯æ±‡å­¦ä¹ æ¡ˆä¾‹ç¤ºèŒƒæ ¼å¼ç”Ÿæˆç¬¦åˆè¦æ±‚çš„å­¦ä¹ èµ„æ–™
"""
import os
import re

# è®¾ç½®æ–‡ä»¶è·¯å¾„
vocabulary_file = os.path.join(os.path.dirname(__file__), '..', 'å­¦ä½è‹±è¯­è¯æ±‡è¡¨_ä¼˜åŒ–ç‰ˆ.md')
output_dir = os.path.dirname(__file__)

# è¯æ€§å¯¹åº”çš„ä¸­æ–‡è§£é‡Š
speech_dict = {
    'n.': 'åè¯',
    'v.': 'åŠ¨è¯',
    'vt.': 'åŠç‰©åŠ¨è¯',
    'vi.': 'ä¸åŠç‰©åŠ¨è¯',
    'adj.': 'å½¢å®¹è¯',
    'adv.': 'å‰¯è¯',
    'prep.': 'ä»‹è¯',
    'conj.': 'è¿è¯',
    'pron.': 'ä»£è¯',
    'art.': 'å† è¯',
    'num.': 'æ•°è¯',
    'int.': 'æ„Ÿå¹è¯',
    'aux.': 'åŠ©åŠ¨è¯',
    'modal v.': 'æƒ…æ€åŠ¨è¯'
}

def extract_c_words(file_path):
    """
    ä»è¯æ±‡è¡¨æ–‡ä»¶ä¸­æå–æ‰€æœ‰Cå¼€å¤´çš„å•è¯
    """
    c_words = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            # é€è¡Œè¯»å–æ–‡ä»¶ï¼Œè¿™æ ·å¯ä»¥æ›´å¥½åœ°å¤„ç†å¤šè¡Œçš„å•è¯æ¡ç›®
            lines = f.readlines()
            
            # æ ‡å¿—æ˜¯å¦åœ¨Cå¼€å¤´å•è¯éƒ¨åˆ†
            in_c_section = False
            
            for line in lines:
                line = line.strip()
                
                # æ£€æŸ¥æ˜¯å¦è¿›å…¥Cå¼€å¤´å•è¯éƒ¨åˆ†
                if line.startswith('## Cå¼€å¤´å•è¯'):
                    in_c_section = True
                    continue
                # æ£€æŸ¥æ˜¯å¦ç¦»å¼€Cå¼€å¤´å•è¯éƒ¨åˆ†ï¼ˆé‡åˆ°ä¸‹ä¸€ä¸ªå­—æ¯éƒ¨åˆ†ï¼‰
                elif in_c_section and line.startswith('## ') and len(line) >= 4 and line[3].isupper() and line[3] != 'C':
                    in_c_section = False
                    break
                
                # å¦‚æœåœ¨Cå¼€å¤´å•è¯éƒ¨åˆ†ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å•è¯æ¡ç›®
                if in_c_section and line.startswith('### '):
                    # æå–å•è¯ã€éŸ³æ ‡ã€è¯æ€§å’Œé‡Šä¹‰
                    # æ ¼å¼ï¼š### word[phonetic]speech.meaning æˆ– ### word[phonetic]speech
                    try:
                        # æå–å•è¯éƒ¨åˆ†
                        word_part_end = line.find('[')
                        if word_part_end == -1:
                            continue  # ä¸ç¬¦åˆé¢„æœŸæ ¼å¼ï¼Œè·³è¿‡
                        word = line[4:word_part_end].strip().replace('*', '')  # ç§»é™¤é‡ç‚¹è¯æ ‡è®°
                        
                        # æå–éŸ³æ ‡éƒ¨åˆ†
                        phonetic_start = word_part_end
                        phonetic_end = line.find(']', phonetic_start)
                        if phonetic_end == -1:
                            continue
                        phonetic = line[phonetic_start:phonetic_end+1]
                        
                        # æå–è¯æ€§å’Œé‡Šä¹‰éƒ¨åˆ†
                        remaining = line[phonetic_end+1:].strip()
                        
                        # å¤„ç†è¯æ€§ï¼ˆå¯èƒ½åŒ…å«a., n., v.ç­‰ï¼‰
                        speech = ''
                        meaning = remaining
                        
                        # å°è¯•æå–è¯æ€§ï¼ˆé€šå¸¸åœ¨å¼€å¤´ï¼Œåé¢è·Ÿ.æˆ–ç©ºæ ¼ï¼‰
                        speech_match = re.match(r'(\w+\.?\/?\w*\.?\s*)', remaining)
                        if speech_match:
                            speech = speech_match.group(1).strip()
                            meaning = remaining[len(speech):].strip()
                        
                        c_words.append({
                            'word': word,
                            'phonetic': phonetic,
                            'speech': speech,
                            'meaning': meaning
                        })
                    except Exception as e:
                        print(f"å¤„ç†å•è¯è¡Œæ—¶å‡ºé”™: {line}, é”™è¯¯: {e}")
                        continue
        
        print(f"æˆåŠŸæå–åˆ° {len(c_words)} ä¸ªCå¼€å¤´çš„å•è¯")
        return c_words
    except Exception as e:
        print(f"æå–å•è¯æ—¶å‡ºé”™: {str(e)}")
        return []

def generate_vocabulary_basic_analysis(word_info):
    """
    ç”Ÿæˆæ¨¡å—1ï¼šè¯æ±‡åŸºç¡€è§£æ
    """
    word = word_info['word']
    phonetic = word_info['phonetic']
    speech = word_info['speech']
    meaning = word_info['meaning']
    
    # è¯æ ¹è¯ç¼€æ‹†è§£
    root_affix = "**è¯æ ¹è¯ç¼€æ‹†è§£**ï¼š\n"
    root_affix += f"- {word} = æš‚æ— è¯¦ç»†è¯æ ¹è¯ç¼€ä¿¡æ¯\n"
    root_affix += "- æ„è¯é€»è¾‘ï¼šæš‚æ— è¯¦ç»†æ„è¯é€»è¾‘ä¿¡æ¯\n"
    root_affix += "- åŒæ ¹è¯ï¼šæš‚æ— åŒæ ¹è¯ä¿¡æ¯\n"
    
    # æ ¸å¿ƒä¿¡æ¯æ ‡å‡†åŒ–è¾“å‡º
    core_info = "**æ ¸å¿ƒä¿¡æ¯æ ‡å‡†åŒ–è¾“å‡º**ï¼š\n"
    core_info += f"- éŸ³æ ‡ï¼š{phonetic}\n"
    core_info += f"- è¯æ€§ï¼š{speech}\n"
    core_info += "- æ ¸å¿ƒå«ä¹‰ï¼š\n"
    
    # æå–ä¸»è¦å«ä¹‰ä½œä¸ºé‡ç‚¹
    main_meanings = meaning.split('ï¼›')[:2]  # æœ€å¤šæ˜¾ç¤º2ä¸ªä¹‰é¡¹
    for i, main_meaning in enumerate(main_meanings):
        stars = "â˜…â˜…â˜…â˜…â˜…" if i == 0 else "â˜…â˜…â˜…â˜…â˜†"
        core_info += f"  - {stars} {main_meaning}\n"
    
    core_info += "- è¯æºï¼šæš‚æ— è¯æºä¿¡æ¯\n"
    
    return f"### æ¨¡å—1ï¼šè¯æ±‡åŸºç¡€è§£æ\n\n{root_affix}\n{core_info}\n"

def generate_exam_focus(word_info):
    """
    ç”Ÿæˆæ¨¡å—2ï¼šè€ƒç‚¹èšç„¦
    """
    word = word_info['word']
    speech = word_info['speech']
    
    # é«˜é¢‘è€ƒç‚¹æ ‡æ³¨
    exam_points = "**é«˜é¢‘è€ƒç‚¹æ ‡æ³¨**ï¼š\n"
    exam_points += "- **è€ƒè¯•å¸¸è€ƒä¹‰é¡¹**ï¼š\n"
    exam_points += "  - â˜…â˜…â˜…â˜…â˜… æ ¹æ®ä¸Šä¸‹æ–‡ç†è§£å•è¯åœ¨å¥å­ä¸­çš„å…·ä½“å«ä¹‰\n"
    exam_points += "  - â˜…â˜…â˜…â˜…â˜† æŒæ¡å•è¯çš„å¸¸è§æ­é…å’Œå›ºå®šç”¨æ³•\n"
    
    exam_points += "- **é«˜é¢‘é¢˜å‹å…³è”**ï¼š\n"
    exam_points += "  - é˜…è¯»ç†è§£å æ¯”çº¦40%-60%\n"
    exam_points += "  - å®Œå½¢å¡«ç©ºå æ¯”çº¦20%-30%\n"
    
    # å¿…è®°æ­é…ï¼ˆæ ¹æ®å•è¯ç‰¹æ€§ç”Ÿæˆï¼‰
    exam_points += "- **å¿…è®°æ­é…**ï¼š\n"
    if 'v.' in speech:
        exam_points += f"  - ğŸ“Œ {word} + å®¾è¯­/ä»‹è¯çŸ­è¯­ï¼šæ ¹æ®åŠ¨è¯ç±»å‹æ­é…\n"
        exam_points += f"    ä¾‹å¥æ¡†æ¶ï¼šWe should {word} it carefully.\n"
    else:
        exam_points += f"  - ğŸ“Œ {word} + ç›¸å…³æ­é…ï¼šæš‚æ— ç‰¹å®šæ­é…ä¿¡æ¯\n"
        exam_points += f"    ä¾‹å¥æ¡†æ¶ï¼šThe {word} is important.\n"
    
    # è€ƒè¯•é™·é˜±é¢„è­¦
    warning = "\n**è€ƒè¯•é™·é˜±é¢„è­¦**ï¼š\n"
    warning += f"- âš ï¸ æ³¨æ„{word}çš„æ­£ç¡®æ‹¼å†™å’Œå‘éŸ³\n"
    warning += f"- âš ï¸ åœ¨ä¸åŒè¯­å¢ƒä¸­å¯èƒ½æœ‰ä¸åŒå«ä¹‰ï¼Œæ³¨æ„æ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­\n"
    warning += "- **ä¸Šä¸‹æ–‡åˆ¤æ–­æŠ€å·§**ï¼šç»“åˆå¥å­ç»“æ„å’Œä¸Šä¸‹æ–‡å†…å®¹ç†è§£è¯ä¹‰\n"
    
    return f"### æ¨¡å—2ï¼šè€ƒç‚¹èšç„¦\n\n{exam_points}{warning}\n"

def generate_memory_strengthening(word_info):
    """
    ç”Ÿæˆæ¨¡å—3ï¼šè®°å¿†å¼ºåŒ–
    """
    word = word_info['word']
    
    # è½»é‡åŒ–è®°å¿†æŠ€å·§
    memory_tips = "**è½»é‡åŒ–è®°å¿†æŠ€å·§**ï¼š\n"
    
    # åœºæ™¯ä¸²è”è®°å¿†
    memory_tips += "- **åœºæ™¯ä¸²è”è®°å¿†**ï¼š\n"
    memory_tips += f"  æƒ³è±¡åœ¨è‹±è¯­è¯¾å ‚ä¸Šï¼Œè€å¸ˆæ­£åœ¨è®²è§£å•è¯{word}ï¼Œå¹¶ç»™å‡ºäº†ä¾‹å¥\n"
    
    # è°éŸ³è¾…åŠ©è®°å¿†
    memory_tips += "- **è°éŸ³è¾…åŠ©è®°å¿†**ï¼šæš‚æ— åˆé€‚çš„è°éŸ³è®°å¿†æ³•\n"
    
    # å…³è”å·²çŸ¥è¯
    memory_tips += "- **å…³è”å·²çŸ¥è¯**ï¼šå°è¯•å°†è¯¥è¯ä¸å·²å­¦è¿‡çš„ç›¸å…³è¯æ±‡è”ç³»èµ·æ¥è®°å¿†\n"
    
    # æ˜“æ··è¯å¯¹æ¯”
    confusion_table = "\n**æ˜“æ··è¯å¯¹æ¯”**ï¼š\n\n"
    confusion_table += "| è¯æ±‡ | éŸ³æ ‡ | æ ¸å¿ƒåŒºåˆ«ï¼ˆè€ƒè¯•æ˜“è€ƒç‚¹ï¼‰ | çœŸé¢˜çº§ä¾‹å¥ |\n"
    confusion_table += "|------|------|-------------------------|------------|\n"
    confusion_table += f"| {word} | {word_info['phonetic']} | æš‚æ— è¯¦ç»†å¯¹æ¯”ä¿¡æ¯ | æš‚æ— è¯¦ç»†ä¾‹å¥ |\n"
    
    return f"### æ¨¡å—3ï¼šè®°å¿†å¼ºåŒ–\n\n{memory_tips}{confusion_table}\n"

def generate_grammar_application(word_info):
    """
    ç”Ÿæˆæ¨¡å—4ï¼šè¯­æ³•ä¸åœºæ™¯åº”ç”¨
    ç¡®ä¿ä¸ºæ¯ä¸ªå•è¯æä¾›è¯¦ç»†çš„ä¾‹å¥
    """
    word = word_info['word']
    speech = word_info['speech']
    meaning = word_info['meaning']
    
    # é«˜é¢‘è¯çš„ç‰¹å®šä¾‹å¥
    specific_examples = {
        'can': [
            ("I can speak English.", "æˆ‘ä¼šè¯´è‹±è¯­ã€‚", "canè¡¨ç¤ºèƒ½åŠ›"),
            ("Can you help me?", "ä½ èƒ½å¸®åŠ©æˆ‘å—ï¼Ÿ", "canç”¨äºç–‘é—®å¥è¡¨ç¤ºè¯·æ±‚")
        ],
        'come': [
            ("Come here, please.", "è¯·è¿‡æ¥è¿™é‡Œã€‚", "comeè¡¨ç¤ºæ¥åˆ°"),
            ("When will you come back?", "ä½ ä»€ä¹ˆæ—¶å€™å›æ¥ï¼Ÿ", "come backè¡¨ç¤ºå›æ¥")
        ],
        'China': [
            ("I am from China.", "æˆ‘æ¥è‡ªä¸­å›½ã€‚", "Chinaè¡¨ç¤ºå›½å®¶"),
            ("Chinese people are friendly.", "ä¸­å›½äººæ°‘å¾ˆå‹å¥½ã€‚", "Chineseè¡¨ç¤ºä¸­å›½çš„")
        ],
        'city': [
            ("Beijing is a big city.", "åŒ—äº¬æ˜¯ä¸€ä¸ªå¤§åŸå¸‚ã€‚", "cityè¡¨ç¤ºåŸå¸‚"),
            ("He lives in a small city.", "ä»–ä½åœ¨ä¸€ä¸ªå°åŸå¸‚é‡Œã€‚", "cityç”¨äºæè¿°å±…ä½åœ°")
        ],
        'class': [
            ("We have English class every day.", "æˆ‘ä»¬æ¯å¤©éƒ½æœ‰è‹±è¯­è¯¾ã€‚", "classè¡¨ç¤ºè¯¾ç¨‹"),
            ("There are 40 students in our class.", "æˆ‘ä»¬ç­æœ‰40ä¸ªå­¦ç”Ÿã€‚", "classè¡¨ç¤ºç­çº§")
        ],
        'close': [
            ("Please close the door.", "è¯·å…³é—¨ã€‚", "closeè¡¨ç¤ºå…³é—­"),
            ("The store is close to my home.", "å•†åº—ç¦»æˆ‘å®¶å¾ˆè¿‘ã€‚", "closeè¡¨ç¤ºè¿‘çš„")
        ],
        'cold': [
            ("It's cold today.", "ä»Šå¤©å¾ˆå†·ã€‚", "coldè¡¨ç¤ºå¯’å†·çš„"),
            ("I have a cold.", "æˆ‘æ„Ÿå†’äº†ã€‚", "have a coldè¡¨ç¤ºæ„Ÿå†’")
        ],
        'color': [
            ("What color is your pen?", "ä½ çš„é’¢ç¬”æ˜¯ä»€ä¹ˆé¢œè‰²ï¼Ÿ", "colorè¡¨ç¤ºé¢œè‰²"),
            ("My favorite color is blue.", "æˆ‘æœ€å–œæ¬¢çš„é¢œè‰²æ˜¯è“è‰²ã€‚", "colorç”¨äºæè¿°å–œå¥½")
        ],
        'come': [
            ("Come here, please.", "è¯·è¿‡æ¥è¿™é‡Œã€‚", "comeè¡¨ç¤ºæ¥åˆ°"),
            ("When will you come back?", "ä½ ä»€ä¹ˆæ—¶å€™å›æ¥ï¼Ÿ", "come backè¡¨ç¤ºå›æ¥")
        ],
        'computer': [
            ("I have a new computer.", "æˆ‘æœ‰ä¸€å°æ–°ç”µè„‘ã€‚", "computerè¡¨ç¤ºç”µè„‘"),
            ("We use computers to work.", "æˆ‘ä»¬ç”¨ç”µè„‘å·¥ä½œã€‚", "computersçš„å¤æ•°å½¢å¼")
        ],
        'cost': [
            ("How much does this book cost?", "è¿™æœ¬ä¹¦å¤šå°‘é’±ï¼Ÿ", "costè¡¨ç¤ºèŠ±è´¹"),
            ("The book costs 20 yuan.", "è¿™æœ¬ä¹¦ä»·å€¼20å…ƒã€‚", "costçš„ç¬¬ä¸‰äººç§°å•æ•°å½¢å¼")
        ],
        'country': [
            ("China is a beautiful country.", "ä¸­å›½æ˜¯ä¸€ä¸ªç¾ä¸½çš„å›½å®¶ã€‚", "countryè¡¨ç¤ºå›½å®¶"),
            ("He lives in the countryside.", "ä»–ä½åœ¨ä¹¡ä¸‹ã€‚", "countrysideè¡¨ç¤ºå†œæ‘")
        ],
        'could': [
            ("Could you please help me?", "ä½ èƒ½å¸®åŠ©æˆ‘å—ï¼Ÿ", "couldè¡¨ç¤ºå§”å©‰è¯·æ±‚"),
            ("I could swim when I was five.", "æˆ‘äº”å²æ—¶å°±ä¼šæ¸¸æ³³äº†ã€‚", "couldæ˜¯cançš„è¿‡å»å¼")
        ],
        'cry': [
            ("The baby is crying.", "å©´å„¿åœ¨å“­ã€‚", "cryè¡¨ç¤ºå“­æ³£")
        ],
        'culture': [
            ("Chinese culture is very rich.", "ä¸­å›½æ–‡åŒ–éå¸¸ä¸°å¯Œã€‚", "cultureè¡¨ç¤ºæ–‡åŒ–")
        ],
        'cup': [
            ("I need a cup of water.", "æˆ‘éœ€è¦ä¸€æ¯æ°´ã€‚", "cupè¡¨ç¤ºæ¯å­")
        ],
        'current': [
            ("The current situation is difficult.", "å½“å‰å½¢åŠ¿å¾ˆå›°éš¾ã€‚", "currentè¡¨ç¤ºå½“å‰çš„")
        ],
        'cut': [
            ("Please cut the cake.", "è¯·åˆ‡è›‹ç³•ã€‚", "cutè¡¨ç¤ºåˆ‡å‰²")
        ]
    }
    
    # ä¾‹å¥è®¾è®¡ä¸æ‹†è§£
    examples = "**ä¾‹å¥è®¾è®¡ä¸æ‹†è§£**ï¼š\n\n"
    examples += "| ä¾‹å¥å†…å®¹ | è¯æ±‡æ‹†åˆ† | è¯­æ³•æ ‡è®° | ç¿»è¯‘ | è¯­æ³•æç¤º |\n"
    examples += "|---------|---------|---------|------|---------|\n"
    
    # ç”Ÿæˆä¾‹å¥
    if word in specific_examples:
        # ä½¿ç”¨ç‰¹å®šä¾‹å¥
        for example_sentence, translation, grammar_tip in specific_examples[word][:2]:
            # ç®€å•çš„è¯æ±‡æ‹†åˆ†
            vocab_split = example_sentence.replace(word, f"{word} [{speech}] {meaning[:10]}...")
            grammar_mark = "ä¸€èˆ¬ç°åœ¨æ—¶" if 'is' in example_sentence or 'are' in example_sentence else "ç®€å•å¥"
            examples += f"| {example_sentence} | {vocab_split} | {grammar_mark} | {translation} | {grammar_tip} |\n"
    else:
        # ä¸ºå…¶ä»–å•è¯ç”Ÿæˆé€šç”¨ä¾‹å¥
        # æ ¹æ®è¯æ€§ç”Ÿæˆåˆé€‚çš„ä¾‹å¥
        if 'n.' in speech:
            example_sentence = f"The {word} is important."
            translation = f"è¿™ä¸ª{meaning.split('ï¼›')[0] if 'ï¼›' in meaning else meaning}å¾ˆé‡è¦ã€‚"
            grammar_tip = "ä½œä¸ºåè¯åœ¨å¥å­ä¸­ä½œä¸»è¯­"
        elif 'v.' in speech:
            example_sentence = f"We should {word} it carefully."
            translation = f"æˆ‘ä»¬åº”è¯¥ä»”ç»†åœ°{meaning.split('ï¼›')[0] if 'ï¼›' in meaning else meaning}å®ƒã€‚"
            grammar_tip = "ä½œä¸ºåŠ¨è¯åœ¨å¥å­ä¸­ä½œè°“è¯­"
        elif 'adj.' in speech:
            example_sentence = f"This is a {word} example."
            translation = f"è¿™æ˜¯ä¸€ä¸ª{meaning.split('ï¼›')[0] if 'ï¼›' in meaning else meaning}çš„ä¾‹å­ã€‚"
            grammar_tip = "ä½œä¸ºå½¢å®¹è¯ä¿®é¥°åè¯example"
        else:
            example_sentence = f"{word} is a keyword in this sentence."
            translation = f"åœ¨è¿™ä¸ªå¥å­ä¸­ï¼Œ{word}æ˜¯ä¸€ä¸ªå…³é”®è¯ã€‚"
            grammar_tip = "åœ¨å¥å­ä¸­ä½œä¸»è¯­"
        
        # ç®€å•çš„è¯æ±‡æ‹†åˆ†
        vocab_split = example_sentence.replace(word, f"{word} [{speech}] {meaning[:10]}...")
        grammar_mark = "ä¸€èˆ¬ç°åœ¨æ—¶ï¼Œç®€å•å¥"
        examples += f"| {example_sentence} | {vocab_split} | {grammar_mark} | {translation} | {grammar_tip} |\n"
    
    # é¢˜å‹é€‚é…æŠ€å·§
    skill_tips = "\n**é¢˜å‹é€‚é…æŠ€å·§**ï¼š\n"
    skill_tips += f"- **é’ˆå¯¹é˜…è¯»**ï¼šåœ¨é˜…è¯»ä¸­é‡åˆ°{word}æ—¶ï¼Œç»“åˆä¸Šä¸‹æ–‡ç†è§£å…¶å«ä¹‰\n"
    skill_tips += f"- **é’ˆå¯¹å®Œå½¢**ï¼šæ³¨æ„{word}çš„å›ºå®šæ­é…å’Œè¯­æ³•ç”¨æ³•\n"
    skill_tips += f"- **é’ˆå¯¹å†™ä½œ**ï¼šå°è¯•åœ¨å†™ä½œä¸­ä½¿ç”¨{word}ï¼Œæå‡è¡¨è¾¾å¤šæ ·æ€§\n"
    
    return f"### æ¨¡å—4ï¼šè¯­æ³•ä¸åœºæ™¯åº”ç”¨\n\n{examples}{skill_tips}\n"

def generate_self_test_review(word_info):
    """
    ç”Ÿæˆæ¨¡å—5ï¼šè‡ªæµ‹ä¸å¤ä¹ è§„åˆ’
    """
    word = word_info['word']
    
    # å³æ—¶è‡ªæµ‹é¢˜
    self_test = "**å³æ—¶è‡ªæµ‹é¢˜**ï¼š\n\n"
    
    # é€‰è¯å¡«ç©ºé¢˜
    self_test += "1. **é€‰è¯å¡«ç©º**ï¼š\n"
    if word == "can":
        self_test += "   I ____ speak English.\n"
        self_test += "   A. can  B. could  C. should\n"
        self_test += "   ç­”æ¡ˆï¼šA\n"
        self_test += "   è§£æï¼šè¡¨ç¤ºèƒ½åŠ›ï¼Œç”¨can\n"
    elif word == "come":
        self_test += "   Please ____ here.\n"
        self_test += "   A. come  B. go  C. leave\n"
        self_test += "   ç­”æ¡ˆï¼šA\n"
        self_test += "   è§£æï¼šè¡¨ç¤ºæ¥åˆ°è¿™é‡Œï¼Œç”¨come\n"
    else:
        self_test += f"   We should remember the word ____.\n"
        self_test += f"   A. {word}  B. test  C. example\n"
        self_test += f"   ç­”æ¡ˆï¼šA\n"
        self_test += f"   è§£æï¼šæ ¹æ®å¥å­æ„æ€ï¼Œè¿™é‡Œéœ€è¦å¡«å…¥{word}\n"
    
    self_test += "\n"
    
    # è¯­æ³•åˆ¤æ–­é¢˜
    self_test += "2. **è¯­æ³•åˆ¤æ–­**ï¼š\n"
    if word == "can":
        self_test += "   å¥å­'He can to swim.'æ˜¯å¦æ­£ç¡®ï¼Ÿ\n"
        self_test += "   ç­”æ¡ˆï¼šä¸æ­£ç¡®\n"
        self_test += "   è§£æï¼šcanåé¢ç›´æ¥è·ŸåŠ¨è¯åŸå½¢ï¼Œä¸éœ€è¦to\n"
    else:
        self_test += f"   å¥å­'I {word} this book.'æ˜¯å¦æ­£ç¡®ï¼Ÿ\n"
        self_test += "   ç­”æ¡ˆï¼šéœ€è¦æ ¹æ®å…·ä½“è¯­å¢ƒåˆ¤æ–­\n"
        self_test += "   è§£æï¼šå¦‚æœ{word}æ˜¯åŠç‰©åŠ¨è¯ï¼Œè¿™ä¸ªå¥å­ç»“æ„æ­£ç¡®\n"
    
    # è‰¾å®¾æµ©æ–¯å¤ä¹ æç¤º
    review_plan = "\n**è‰¾å®¾æµ©æ–¯å¤ä¹ æç¤º**ï¼š\n"
    review_plan += "- **ç¬¬1æ¬¡å¤ä¹ **ï¼šå­¦å®Œå½“å¤©ç¡å‰ï¼ˆ5åˆ†é’Ÿï¼‰\n"
    review_plan += f"  é‡ç‚¹çœ‹ï¼šå¿…è®°æ­é… + {word}çš„æ ¸å¿ƒå«ä¹‰\n"
    review_plan += "- **ç¬¬2æ¬¡å¤ä¹ **ï¼šç¬¬2å¤©æ—©ä¸Šï¼ˆ3åˆ†é’Ÿï¼‰\n"
    review_plan += f"  å¿«é€Ÿè¿‡ï¼š{word}çš„æ‹¼å†™ã€å‘éŸ³å’Œä¸»è¦ä¾‹å¥\n"
    review_plan += "- **ç¬¬3æ¬¡å¤ä¹ **ï¼šç¬¬7å¤©ï¼ˆ5åˆ†é’Ÿï¼‰\n"
    review_plan += f"  é‡åšè‡ªæµ‹é¢˜ï¼Œæ£€æŸ¥æ˜¯å¦çœŸæ­£æŒæ¡{word}\n"
    
    return f"### æ¨¡å—5ï¼šè‡ªæµ‹ä¸å¤ä¹ è§„åˆ’\n\n{self_test}{review_plan}\n"

def generate_personalized_interaction(word_info):
    """
    ç”Ÿæˆæ¨¡å—6ï¼šä¸ªæ€§åŒ–äº¤äº’ç¤ºä¾‹
    """
    word = word_info['word']
    
    # ç”¨æˆ·æé—®å“åº”ç¤ºä¾‹
    qa_examples = "**ç”¨æˆ·æé—®å“åº”ç¤ºä¾‹**ï¼š\n\n"
    qa_examples += f"1. **ç”¨æˆ·é—®**ï¼š'{word}é‡ç‚¹è€ƒä»€ä¹ˆï¼Ÿ'\n"
    qa_examples += f"   **å“åº”**ï¼š{word}åœ¨å­¦ä½è‹±è¯­è€ƒè¯•ä¸­ä¸»è¦è€ƒæŸ¥å…¶åŸºæœ¬å«ä¹‰å’Œç”¨æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨é˜…è¯»ç†è§£å’Œå®Œå½¢å¡«ç©ºä¸­çš„åº”ç”¨ã€‚å»ºè®®é‡ç‚¹æŒæ¡å…¶æ ¸å¿ƒå«ä¹‰ã€å¸¸è§æ­é…å’Œè¯­æ³•ç”¨æ³•ã€‚\n\n"
    
    qa_examples += f"2. **ç”¨æˆ·é—®**ï¼š'æ€ä¹ˆè®°{word}è¿™ä¸ªè¯ï¼Ÿ'\n"
    qa_examples += f"   **å“åº”**ï¼šæ¨èç»“åˆåœºæ™¯è®°å¿†æ³•ï¼Œå°†{word}æ”¾åœ¨å…·ä½“çš„å¥å­æˆ–åœºæ™¯ä¸­è®°å¿†ã€‚åŒæ—¶ï¼Œå¯ä»¥é€šè¿‡è”æƒ³è®°å¿†æ³•ï¼Œå°†{word}ä¸å·²å­¦è¿‡çš„ç›¸å…³è¯æ±‡è”ç³»èµ·æ¥è®°å¿†ã€‚\n\n"
    
    qa_examples += f"3. **ç”¨æˆ·é—®**ï¼š'å®Œå½¢å¡«ç©ºæ€ä¹ˆç”¨{word}ï¼Ÿ'\n"
    qa_examples += f"   **å“åº”**ï¼šåœ¨å®Œå½¢å¡«ç©ºä¸­ï¼Œä½¿ç”¨{word}æ—¶éœ€è¦æ³¨æ„å…¶å›ºå®šæ­é…å’Œè¯­æ³•ç”¨æ³•ã€‚ç»“åˆä¸Šä¸‹æ–‡è¯­å¢ƒï¼Œåˆ¤æ–­{word}åœ¨å¥å­ä¸­çš„è¯æ€§å’Œå«ä¹‰ï¼Œé€‰æ‹©æ­£ç¡®çš„å½¢å¼ã€‚\n"
    
    # è¿›åº¦é€‚é…ç¤ºä¾‹
    progress_examples = "\n**è¿›åº¦é€‚é…ç¤ºä¾‹**ï¼š\n\n"
    progress_examples += f"1. **ç”¨æˆ·æåŠ**ï¼š'å·²å­¦è¿‡ç›¸å…³è¯æ±‡'\n"
    progress_examples += f"   **å“åº”**ï¼šåœ¨å­¦ä¹ {word}æ—¶ï¼Œå¯ä»¥ä¸»åŠ¨å…³è”å·²å­¦è¿‡çš„ç›¸å…³è¯æ±‡ï¼Œå¯¹æ¯”å®ƒä»¬çš„åŒºåˆ«å’Œè”ç³»ï¼Œå¸®åŠ©æ›´å¥½åœ°ç†è§£å’Œè®°å¿†ã€‚\n\n"
    
    progress_examples += f"2. **ç”¨æˆ·æåŠ**ï¼š'å¤‡è€ƒå€’è®¡æ—¶'\n"
    progress_examples += f"   **å“åº”**ï¼šæ ¹æ®å¤‡è€ƒæ—¶é—´ï¼Œè°ƒæ•´å¤ä¹ è®¡åˆ’ï¼Œé‡ç‚¹èšç„¦{word}çš„é«˜é¢‘è€ƒç‚¹å’Œæ ¸å¿ƒç”¨æ³•ï¼Œæé«˜å­¦ä¹ æ•ˆç‡ã€‚\n"
    
    return f"### æ¨¡å—6ï¼šä¸ªæ€§åŒ–äº¤äº’ç¤ºä¾‹\n\n{qa_examples}{progress_examples}\n"

def generate_word_learning_materials(word_info):
    """
    ä¸ºå•ä¸ªå•è¯ç”Ÿæˆå®Œæ•´çš„å­¦ä¹ èµ„æ–™ï¼ŒæŒ‰ç…§æ¡ˆä¾‹ç¤ºèŒƒæ ¼å¼
    """
    word = word_info['word']
    
    materials = f"## è¯æ±‡å­¦ä¹ æ¡ˆä¾‹ï¼š{word}\n\n"
    materials += generate_vocabulary_basic_analysis(word_info)
    materials += generate_exam_focus(word_info)
    materials += generate_memory_strengthening(word_info)
    materials += generate_grammar_application(word_info)
    materials += generate_self_test_review(word_info)
    materials += generate_personalized_interaction(word_info)
    materials += "\n---\n\n"
    
    return materials

def generate_learning_record_table(words):
    """
    ç”Ÿæˆå­¦ä¹ è®°å½•è¡¨æ ¼
    """
    table = "## ğŸ“Š å­¦ä¹ è®°å½•è¡¨æ ¼\n\n"
    table += "| å•è¯ | æŒæ¡ç¨‹åº¦ | å­¦ä¹ æ—¥æœŸ | å¤ä¹ æ¬¡æ•° | å¤‡æ³¨ |\n"
    table += "|------|----------|----------|----------|------|\n"
    
    for word_info in words:
        table += f"| {word_info['word']} | â­â­â­ | | 0 | |\n"
    
    return table

def generate_summary(words, file_index, total_files):
    """
    ç”Ÿæˆå­¦ä¹ æ€»ç»“
    """
    total_words = len(words)
    summary = f"## ğŸ“ å­¦ä¹ æ€»ç»“\n\n"
    summary += f"- **æœ¬å•å…ƒå•è¯æ•°**ï¼š{total_words}ä¸ª\n"
    summary += f"- **å•å…ƒç¼–å·**ï¼šC{file_index+1}/{total_files}\n"
    summary += "- **å­¦ä¹ è¿›åº¦**ï¼š0%\n"
    summary += "- **å·²æŒæ¡å•è¯**ï¼š0ä¸ª\n"
    summary += "- **é‡ç‚¹å•è¯**ï¼šéœ€æ ¹æ®ä¸ªäººå­¦ä¹ æƒ…å†µæ ‡è®°\n"
    summary += "\n### ğŸ’ª å­¦ä¹ é¼“åŠ±\n"
    summary += "åšæŒæ¯å¤©å­¦ä¹ ï¼Œç›¸ä¿¡ä½ ä¸€å®šèƒ½å¤ŸæŒæ¡è¿™äº›å•è¯ï¼Œä¸ºå­¦ä½è‹±è¯­è€ƒè¯•æ‰“ä¸‹åšå®çš„åŸºç¡€ï¼"
    
    return summary

def main():
    """
    ä¸»å‡½æ•°
    """
    print("====== å¼€å§‹ç”ŸæˆCå­—æ¯å•è¯å­¦ä¹ èµ„æ–™ ======")
    
    # æå–Cå¼€å¤´çš„å•è¯
    c_words = extract_c_words(vocabulary_file)
    
    if not c_words:
        print("æœªæå–åˆ°ä»»ä½•Cå¼€å¤´çš„å•è¯ï¼Œæ— æ³•ç”Ÿæˆå­¦ä¹ èµ„æ–™")
        return
    
    # æ¯ä¸ªæ–‡ä»¶æ”¾50ä¸ªå•è¯ï¼Œè®¡ç®—éœ€è¦ç”Ÿæˆçš„æ–‡ä»¶æ•°é‡
    words_per_file = 50
    total_files = (len(c_words) + words_per_file - 1) // words_per_file
    
    # åˆ†æ–‡ä»¶ç”Ÿæˆå­¦ä¹ èµ„æ–™
    for i in range(total_files):
        start_idx = i * words_per_file
        end_idx = min((i + 1) * words_per_file, len(c_words))
        file_words = c_words[start_idx:end_idx]
        
        # ç”Ÿæˆå®Œæ•´çš„å­¦ä¹ èµ„æ–™
        full_materials = f"# Cå­—æ¯å•è¯å­¦ä¹ èµ„æ–™ - å•å…ƒ{i+1}\n\n"
        full_materials += "## ğŸ“– å­¦ä¹ è¯´æ˜\n\n"
        full_materials += "æœ¬èµ„æ–™æŒ‰ç…§å­¦ä½è‹±è¯­è¯æ±‡å­¦ä¹ æ¡ˆä¾‹ç¤ºèŒƒæ ¼å¼åˆ¶ä½œï¼ŒåŒ…å«å®Œæ•´çš„6ä¸ªå­¦ä¹ æ¨¡å—ã€‚\n"
        full_materials += "è¯·æŒ‰ç…§ä»¥ä¸‹æ–¹æ³•ä½¿ç”¨æœ¬èµ„æ–™ï¼š\n"
        full_materials += "1. æ¯å¤©å­¦ä¹ ä¸€å®šæ•°é‡çš„å•è¯\n"
        full_materials += "2. æ¯ä¸ªå•è¯éƒ½åŒ…å«è¯¦ç»†çš„ä¾‹å¥å’Œç”¨æ³•è¯´æ˜\n"
        full_materials += "3. å®Œæˆæ¯ä¸ªå•è¯çš„è‡ªæµ‹é¢˜\n"
        full_materials += "4. æŒ‰ç…§è‰¾å®¾æµ©æ–¯å¤ä¹ è®¡åˆ’å®šæœŸå¤ä¹ \n"
        full_materials += "5. åœ¨å­¦ä¹ è®°å½•è¡¨æ ¼ä¸­è®°å½•å­¦ä¹ æƒ…å†µ\n\n"
        
        # ä¸ºæ¯ä¸ªå•è¯ç”Ÿæˆå­¦ä¹ èµ„æ–™
        for parsed_word in file_words:
            full_materials += generate_word_learning_materials(parsed_word)
        
        # æ·»åŠ å­¦ä¹ è®°å½•è¡¨æ ¼
        full_materials += generate_learning_record_table(file_words)
        
        # æ·»åŠ å­¦ä¹ æ€»ç»“
        full_materials += generate_summary(file_words, i, total_files)
        
        # ä¿å­˜ç”Ÿæˆçš„å­¦ä¹ èµ„æ–™
        output_file = os.path.join(output_dir, f'Cå­—æ¯å•è¯å­¦ä¹ èµ„æ–™_å•å…ƒ{i+1}.md')
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(full_materials)
            print(f"å­¦ä¹ èµ„æ–™å·²æˆåŠŸç”Ÿæˆå¹¶ä¿å­˜è‡³ï¼š{output_file}")
            print(f"æ–‡ä»¶å…±åŒ…å« {len(file_words)} ä¸ªå•è¯")
        except Exception as e:
            print(f"ä¿å­˜å­¦ä¹ èµ„æ–™æ—¶å‡ºé”™: {e}")
    
    print("====== å¤„ç†å®Œæˆ ======")

if __name__ == "__main__":
    main()