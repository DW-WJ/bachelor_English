#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”¨äºç”ŸæˆAå­—æ¯å•è¯å­¦ä¹ èµ„æ–™çš„è„šæœ¬
æ ¹æ®å­¦ä½è‹±è¯­è¯æ±‡å­¦ä¹ æ¡ˆä¾‹ç¤ºèŒƒæ ¼å¼ç”Ÿæˆç¬¦åˆè¦æ±‚çš„å­¦ä¹ èµ„æ–™
"""
import os
import re

# è®¾ç½®æ–‡ä»¶è·¯å¾„
vocabulary_file = os.path.join(os.path.dirname(__file__), '..', 'å­¦ä½è‹±è¯­è¯æ±‡è¡¨_ä¼˜åŒ–ç‰ˆ.md')
output_dir = os.path.dirname(__file__)

# è¯æ€§å¯¹åº”çš„ä¸­æ–‡è§£é‡Š
speech_dict = {
    'n.': 'åè¯',
    'v.': 'åŠ¨è¯',
    'vt.': 'åŠç‰©åŠ¨è¯',
    'vi.': 'ä¸åŠç‰©åŠ¨è¯',
    'adj.': 'å½¢å®¹è¯',
    'adv.': 'å‰¯è¯',
    'prep.': 'ä»‹è¯',
    'conj.': 'è¿è¯',
    'pron.': 'ä»£è¯',
    'art.': 'å† è¯',
    'num.': 'æ•°è¯',
    'int.': 'æ„Ÿå¹è¯',
    'aux.': 'åŠ©åŠ¨è¯',
    'modal v.': 'æƒ…æ€åŠ¨è¯'
}

def extract_a_words(file_path):
    """
    ä»è¯æ±‡è¡¨æ–‡ä»¶ä¸­æå–æ‰€æœ‰Aå¼€å¤´çš„å•è¯
    """
    a_words = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            # é€è¡Œè¯»å–æ–‡ä»¶ï¼Œè¿™æ ·å¯ä»¥æ›´å¥½åœ°å¤„ç†å¤šè¡Œçš„å•è¯æ¡ç›®
            lines = f.readlines()
            
            # æ ‡å¿—æ˜¯å¦åœ¨Aå¼€å¤´å•è¯éƒ¨åˆ†
            in_a_section = False
            
            for line in lines:
                line = line.strip()
                
                # æ£€æŸ¥æ˜¯å¦è¿›å…¥Aå¼€å¤´å•è¯éƒ¨åˆ†
                if line.startswith('## Aå¼€å¤´å•è¯'):
                    in_a_section = True
                    continue
                # æ£€æŸ¥æ˜¯å¦ç¦»å¼€Aå¼€å¤´å•è¯éƒ¨åˆ†ï¼ˆé‡åˆ°ä¸‹ä¸€ä¸ªå­—æ¯éƒ¨åˆ†ï¼‰
                elif in_a_section and line.startswith('## ') and len(line) >= 4 and line[3].isupper() and line[3] != 'A':
                    in_a_section = False
                    break
                
                # å¦‚æœåœ¨Aå¼€å¤´å•è¯éƒ¨åˆ†ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å•è¯æ¡ç›®
                if in_a_section and line.startswith('### '):
                    # æå–å•è¯ã€éŸ³æ ‡ã€è¯æ€§å’Œé‡Šä¹‰
                    # æ ¼å¼ï¼š### word[phonetic]speech.meaning æˆ– ### word[phonetic]speech
                    try:
                        # æå–å•è¯éƒ¨åˆ†
                        word_part_end = line.find('[')
                        if word_part_end == -1:
                            continue  # ä¸ç¬¦åˆé¢„æœŸæ ¼å¼ï¼Œè·³è¿‡
                        word = line[4:word_part_end].strip().replace('*', '')  # ç§»é™¤é‡ç‚¹è¯æ ‡è®°
                        
                        # æå–éŸ³æ ‡éƒ¨åˆ†
                        phonetic_start = word_part_end
                        phonetic_end = line.find(']', phonetic_start)
                        if phonetic_end == -1:
                            continue
                        phonetic = line[phonetic_start:phonetic_end+1]
                        
                        # æå–è¯æ€§å’Œé‡Šä¹‰éƒ¨åˆ†
                        remaining = line[phonetic_end+1:].strip()
                        
                        # å¤„ç†è¯æ€§ï¼ˆå¯èƒ½åŒ…å«a., n., v.ç­‰ï¼‰
                        speech = ''
                        meaning = remaining
                        
                        # å°è¯•æå–è¯æ€§ï¼ˆé€šå¸¸åœ¨å¼€å¤´ï¼Œåé¢è·Ÿ.æˆ–ç©ºæ ¼ï¼‰
                        speech_match = re.match(r'(\w+\.?\/?\w*\.?\s*)', remaining)
                        if speech_match:
                            speech = speech_match.group(1).strip()
                            meaning = remaining[len(speech):].strip()
                        
                        a_words.append({
                            'word': word,
                            'phonetic': phonetic,
                            'speech': speech,
                            'meaning': meaning
                        })
                    except Exception as e:
                        print(f"å¤„ç†å•è¯è¡Œæ—¶å‡ºé”™: {line}, é”™è¯¯: {e}")
                        continue
        
        print(f"æˆåŠŸæå–åˆ° {len(a_words)} ä¸ªAå¼€å¤´çš„å•è¯")
        return a_words
    except Exception as e:
        print(f"æå–å•è¯æ—¶å‡ºé”™: {str(e)}")
        return []

def generate_vocabulary_basic_analysis(word_info):
    """
    ç”Ÿæˆæ¨¡å—1ï¼šè¯æ±‡åŸºç¡€è§£æ
    """
    word = word_info['word']
    phonetic = word_info['phonetic']
    speech = word_info['speech']
    meaning = word_info['meaning']
    
    # è¯æ ¹è¯ç¼€æ‹†è§£
    root_affix = "**è¯æ ¹è¯ç¼€æ‹†è§£**ï¼š\n"
    root_affix += f"- {word} = æš‚æ— è¯¦ç»†è¯æ ¹è¯ç¼€ä¿¡æ¯\n"
    root_affix += "- æ„è¯é€»è¾‘ï¼šæš‚æ— è¯¦ç»†æ„è¯é€»è¾‘ä¿¡æ¯\n"
    root_affix += "- åŒæ ¹è¯ï¼šæš‚æ— åŒæ ¹è¯ä¿¡æ¯\n"
    
    # æ ¸å¿ƒä¿¡æ¯æ ‡å‡†åŒ–è¾“å‡º
    core_info = "**æ ¸å¿ƒä¿¡æ¯æ ‡å‡†åŒ–è¾“å‡º**ï¼š\n"
    core_info += f"- éŸ³æ ‡ï¼š{phonetic}\n"
    core_info += f"- è¯æ€§ï¼š{speech}\n"
    core_info += "- æ ¸å¿ƒå«ä¹‰ï¼š\n"
    
    # æå–ä¸»è¦å«ä¹‰ä½œä¸ºé‡ç‚¹
    main_meanings = meaning.split('ï¼›')[:2]  # æœ€å¤šæ˜¾ç¤º2ä¸ªä¹‰é¡¹
    for i, main_meaning in enumerate(main_meanings):
        stars = "â˜…â˜…â˜…â˜…â˜…" if i == 0 else "â˜…â˜…â˜…â˜…â˜†"
        core_info += f"  - {stars} {main_meaning}\n"
    
    core_info += "- è¯æºï¼šæš‚æ— è¯æºä¿¡æ¯\n"
    
    return f"### æ¨¡å—1ï¼šè¯æ±‡åŸºç¡€è§£æ\n\n{root_affix}\n{core_info}\n"

def generate_exam_focus(word_info):
    """
    ç”Ÿæˆæ¨¡å—2ï¼šè€ƒç‚¹èšç„¦
    """
    word = word_info['word']
    speech = word_info['speech']
    
    # é«˜é¢‘è€ƒç‚¹æ ‡æ³¨
    exam_points = "**é«˜é¢‘è€ƒç‚¹æ ‡æ³¨**ï¼š\n"
    exam_points += "- **è€ƒè¯•å¸¸è€ƒä¹‰é¡¹**ï¼š\n"
    exam_points += "  - â˜…â˜…â˜…â˜…â˜… æ ¹æ®ä¸Šä¸‹æ–‡ç†è§£å•è¯åœ¨å¥å­ä¸­çš„å…·ä½“å«ä¹‰\n"
    exam_points += "  - â˜…â˜…â˜…â˜…â˜† æŒæ¡å•è¯çš„å¸¸è§æ­é…å’Œå›ºå®šç”¨æ³•\n"
    
    exam_points += "- **é«˜é¢‘é¢˜å‹å…³è”**ï¼š\n"
    exam_points += "  - é˜…è¯»ç†è§£å æ¯”çº¦40%-60%\n"
    exam_points += "  - å®Œå½¢å¡«ç©ºå æ¯”çº¦20%-30%\n"
    
    # å¿…è®°æ­é…ï¼ˆæ ¹æ®å•è¯ç‰¹æ€§ç”Ÿæˆï¼‰
    exam_points += "- **å¿…è®°æ­é…**ï¼š\n"
    if word == "a" or word == "a/an":
        exam_points += "  - ğŸ“Œ a/an + å¯æ•°åè¯å•æ•°ï¼šè¡¨ç¤ºæ³›æŒ‡\n"
        exam_points += "    ä¾‹å¥æ¡†æ¶ï¼šI need a book.\n"
    elif 'v.' in speech:
        exam_points += f"  - ğŸ“Œ {word} + å®¾è¯­/ä»‹è¯çŸ­è¯­ï¼šæ ¹æ®åŠ¨è¯ç±»å‹æ­é…\n"
        exam_points += f"    ä¾‹å¥æ¡†æ¶ï¼šWe should {word} it carefully.\n"
    else:
        exam_points += f"  - ğŸ“Œ {word} + ç›¸å…³æ­é…ï¼šæš‚æ— ç‰¹å®šæ­é…ä¿¡æ¯\n"
        exam_points += f"    ä¾‹å¥æ¡†æ¶ï¼šThe {word} is important.\n"
    
    # è€ƒè¯•é™·é˜±é¢„è­¦
    warning = "\n**è€ƒè¯•é™·é˜±é¢„è­¦**ï¼š\n"
    warning += f"- âš ï¸ æ³¨æ„{word}çš„æ­£ç¡®æ‹¼å†™å’Œå‘éŸ³\n"
    warning += f"- âš ï¸ åœ¨ä¸åŒè¯­å¢ƒä¸­å¯èƒ½æœ‰ä¸åŒå«ä¹‰ï¼Œæ³¨æ„æ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­\n"
    warning += "- **ä¸Šä¸‹æ–‡åˆ¤æ–­æŠ€å·§**ï¼šç»“åˆå¥å­ç»“æ„å’Œä¸Šä¸‹æ–‡å†…å®¹ç†è§£è¯ä¹‰\n"
    
    return f"### æ¨¡å—2ï¼šè€ƒç‚¹èšç„¦\n\n{exam_points}{warning}\n"

def generate_memory_strengthening(word_info):
    """
    ç”Ÿæˆæ¨¡å—3ï¼šè®°å¿†å¼ºåŒ–
    """
    word = word_info['word']
    
    # è½»é‡åŒ–è®°å¿†æŠ€å·§
    memory_tips = "**è½»é‡åŒ–è®°å¿†æŠ€å·§**ï¼š\n"
    
    # åœºæ™¯ä¸²è”è®°å¿†
    memory_tips += "- **åœºæ™¯ä¸²è”è®°å¿†**ï¼š\n"
    if word == "a" or word == "a/an":
        memory_tips += "  æƒ³è±¡è‡ªå·±åœ¨å•†åº—ä¹°ä¸œè¥¿ï¼Œå¯¹åº—å‘˜è¯´ï¼š'I want a book.'ï¼ˆæˆ‘æƒ³è¦ä¸€æœ¬ä¹¦ï¼‰\n"
    else:
        memory_tips += f"  æƒ³è±¡åœ¨è‹±è¯­è¯¾å ‚ä¸Šï¼Œè€å¸ˆæ­£åœ¨è®²è§£å•è¯{word}ï¼Œå¹¶ç»™å‡ºäº†ä¾‹å¥\n"
    
    # è°éŸ³è¾…åŠ©è®°å¿†
    memory_tips += "- **è°éŸ³è¾…åŠ©è®°å¿†**ï¼šæš‚æ— åˆé€‚çš„è°éŸ³è®°å¿†æ³•\n"
    
    # å…³è”å·²çŸ¥è¯
    memory_tips += "- **å…³è”å·²çŸ¥è¯**ï¼šå°è¯•å°†è¯¥è¯ä¸å·²å­¦è¿‡çš„ç›¸å…³è¯æ±‡è”ç³»èµ·æ¥è®°å¿†\n"
    
    # æ˜“æ··è¯å¯¹æ¯”
    confusion_table = "\n**æ˜“æ··è¯å¯¹æ¯”**ï¼š\n\n"
    confusion_table += "| è¯æ±‡ | éŸ³æ ‡ | æ ¸å¿ƒåŒºåˆ«ï¼ˆè€ƒè¯•æ˜“è€ƒç‚¹ï¼‰ | çœŸé¢˜çº§ä¾‹å¥ |\n"
    confusion_table += "|------|------|-------------------------|------------|\n"
    confusion_table += f"| {word} | {word_info['phonetic']} | æš‚æ— è¯¦ç»†å¯¹æ¯”ä¿¡æ¯ | æš‚æ— è¯¦ç»†ä¾‹å¥ |\n"
    
    return f"### æ¨¡å—3ï¼šè®°å¿†å¼ºåŒ–\n\n{memory_tips}{confusion_table}\n"

def generate_grammar_application(word_info):
    """
    ç”Ÿæˆæ¨¡å—4ï¼šè¯­æ³•ä¸åœºæ™¯åº”ç”¨
    ç¡®ä¿ä¸ºæ¯ä¸ªå•è¯æä¾›è¯¦ç»†çš„ä¾‹å¥
    """
    word = word_info['word']
    speech = word_info['speech']
    meaning = word_info['meaning']
    
    # é«˜é¢‘è¯çš„ç‰¹å®šä¾‹å¥
    specific_examples = {
        'a/an': [
            ("I have a book.", "æˆ‘æœ‰ä¸€æœ¬ä¹¦ã€‚", "aç”¨äºè¾…éŸ³éŸ³ç´ å¼€å¤´çš„å•è¯å‰"),
            ("She is an English teacher.", "å¥¹æ˜¯ä¸€åè‹±è¯­è€å¸ˆã€‚", "anç”¨äºå…ƒéŸ³éŸ³ç´ å¼€å¤´çš„å•è¯å‰")
        ],
        'about': [
            ("What are you talking about?", "ä½ ä»¬åœ¨è°ˆè®ºä»€ä¹ˆï¼Ÿ", "talk aboutæ˜¯å›ºå®šæ­é…"),
            ("There are about 50 students in the class.", "ç­é‡Œå¤§çº¦æœ‰50ä¸ªå­¦ç”Ÿã€‚", "aboutè¡¨ç¤ºå¤§çº¦æ•°é‡")
        ],
        'above': [
            ("The picture is above the desk.", "å›¾ç‰‡åœ¨ä¹¦æ¡Œä¸Šæ–¹ã€‚", "aboveè¡¨ç¤ºåœ¨...ä¸Šæ–¹ï¼ˆä¸æ¥è§¦ï¼‰"),
            ("Above all, you must be honest.", "æœ€é‡è¦çš„æ˜¯ï¼Œä½ å¿…é¡»è¯šå®ã€‚", "above allæ˜¯å›ºå®šçŸ­è¯­")
        ],
        'after': [
            ("I'll see you after lunch.", "åˆé¥­åè§ã€‚", "afterè¡¨ç¤ºåœ¨...ä¹‹å"),
            ("The day after tomorrow is Sunday.", "åå¤©æ˜¯æ˜ŸæœŸæ—¥ã€‚", "after tomorrowè¡¨ç¤ºåå¤©")
        ],
        'again': [
            ("Please say it again.", "è¯·å†è¯´ä¸€éã€‚", "againè¡¨ç¤ºå†æ¬¡"),
            ("He tried again and succeeded.", "ä»–å†æ¬¡å°è¯•å¹¶æˆåŠŸäº†ã€‚", "try againè¡¨ç¤ºå†æ¬¡å°è¯•")
        ],
        'all': [
            ("All of us are happy.", "æˆ‘ä»¬æ‰€æœ‰äººéƒ½å¾ˆé«˜å…´ã€‚", "all ofè¡¨ç¤ºå…¨éƒ¨"),
            ("She ate all the cake.", "å¥¹åƒå…‰äº†æ‰€æœ‰çš„è›‹ç³•ã€‚", "allè¡¨ç¤ºå…¨éƒ¨")
        ],
        'also': [
            ("He is clever and also hardworking.", "ä»–å¾ˆèªæ˜ï¼Œä¹Ÿå¾ˆå‹¤å¥‹ã€‚", "alsoè¡¨ç¤ºä¹Ÿ"),
            ("I also want to go there.", "æˆ‘ä¹Ÿæƒ³å»é‚£é‡Œã€‚", "alsoæ”¾åœ¨å®ä¹‰åŠ¨è¯å‰")
        ]
    }
    
    # ä¾‹å¥è®¾è®¡ä¸æ‹†è§£
    examples = "**ä¾‹å¥è®¾è®¡ä¸æ‹†è§£**ï¼š\n\n"
    examples += "| ä¾‹å¥å†…å®¹ | è¯æ±‡æ‹†åˆ† | è¯­æ³•æ ‡è®° | ç¿»è¯‘ | è¯­æ³•æç¤º |\n"
    examples += "|---------|---------|---------|------|---------|\n"
    
    # ç”Ÿæˆä¾‹å¥
    if word in specific_examples:
        # ä½¿ç”¨ç‰¹å®šä¾‹å¥
        for example_sentence, translation, grammar_tip in specific_examples[word][:2]:
            # ç®€å•çš„è¯æ±‡æ‹†åˆ†
            vocab_split = example_sentence.replace(word, f"{word} [{speech}] {meaning[:10]}...")
            grammar_mark = "ä¸€èˆ¬ç°åœ¨æ—¶" if 'is' in example_sentence or 'are' in example_sentence else "ç®€å•å¥"
            examples += f"| {example_sentence} | {vocab_split} | {grammar_mark} | {translation} | {grammar_tip} |\n"
    else:
        # ä¸ºå…¶ä»–å•è¯ç”Ÿæˆé€šç”¨ä¾‹å¥
        # æ ¹æ®è¯æ€§ç”Ÿæˆåˆé€‚çš„ä¾‹å¥
        if 'n.' in speech:
            example_sentence = f"The {word} is important."
            translation = f"è¿™ä¸ª{meaning.split('ï¼›')[0] if 'ï¼›' in meaning else meaning}å¾ˆé‡è¦ã€‚"
            grammar_tip = "ä½œä¸ºåè¯åœ¨å¥å­ä¸­ä½œä¸»è¯­"
        elif 'v.' in speech:
            example_sentence = f"We should {word} it carefully."
            translation = f"æˆ‘ä»¬åº”è¯¥ä»”ç»†åœ°{meaning.split('ï¼›')[0] if 'ï¼›' in meaning else meaning}å®ƒã€‚"
            grammar_tip = "ä½œä¸ºåŠ¨è¯åœ¨å¥å­ä¸­ä½œè°“è¯­"
        elif 'adj.' in speech:
            example_sentence = f"This is a {word} example."
            translation = f"è¿™æ˜¯ä¸€ä¸ª{meaning.split('ï¼›')[0] if 'ï¼›' in meaning else meaning}çš„ä¾‹å­ã€‚"
            grammar_tip = "ä½œä¸ºå½¢å®¹è¯ä¿®é¥°åè¯example"
        else:
            example_sentence = f"{word} is a keyword in this sentence."
            translation = f"åœ¨è¿™ä¸ªå¥å­ä¸­ï¼Œ{word}æ˜¯ä¸€ä¸ªå…³é”®è¯ã€‚"
            grammar_tip = "åœ¨å¥å­ä¸­ä½œä¸»è¯­"
        
        # ç®€å•çš„è¯æ±‡æ‹†åˆ†
        vocab_split = example_sentence.replace(word, f"{word} [{speech}] {meaning[:10]}...")
        grammar_mark = "ä¸€èˆ¬ç°åœ¨æ—¶ï¼Œç®€å•å¥"
        examples += f"| {example_sentence} | {vocab_split} | {grammar_mark} | {translation} | {grammar_tip} |\n"
    
    # é¢˜å‹é€‚é…æŠ€å·§
    skill_tips = "\n**é¢˜å‹é€‚é…æŠ€å·§**ï¼š\n"
    skill_tips += f"- **é’ˆå¯¹é˜…è¯»**ï¼šåœ¨é˜…è¯»ä¸­é‡åˆ°{word}æ—¶ï¼Œç»“åˆä¸Šä¸‹æ–‡ç†è§£å…¶å«ä¹‰\n"
    skill_tips += f"- **é’ˆå¯¹å®Œå½¢**ï¼šæ³¨æ„{word}çš„å›ºå®šæ­é…å’Œè¯­æ³•ç”¨æ³•\n"
    skill_tips += f"- **é’ˆå¯¹å†™ä½œ**ï¼šå°è¯•åœ¨å†™ä½œä¸­ä½¿ç”¨{word}ï¼Œæå‡è¡¨è¾¾å¤šæ ·æ€§\n"
    
    return f"### æ¨¡å—4ï¼šè¯­æ³•ä¸åœºæ™¯åº”ç”¨\n\n{examples}{skill_tips}\n"

def generate_self_test_review(word_info):
    """
    ç”Ÿæˆæ¨¡å—5ï¼šè‡ªæµ‹ä¸å¤ä¹ è§„åˆ’
    """
    word = word_info['word']
    
    # å³æ—¶è‡ªæµ‹é¢˜
    self_test = "**å³æ—¶è‡ªæµ‹é¢˜**ï¼š\n\n"
    
    # é€‰è¯å¡«ç©ºé¢˜
    self_test += "1. **é€‰è¯å¡«ç©º**ï¼š\n"
    if word == "a" or word == "a/an":
        self_test += "   I need ____ book.\n"
        self_test += "   A. a  B. an  C. the\n"
        self_test += "   ç­”æ¡ˆï¼šA\n"
        self_test += "   è§£æï¼šbookæ˜¯ä»¥è¾…éŸ³éŸ³ç´ å¼€å¤´çš„å•è¯ï¼Œæ‰€ä»¥ç”¨a\n"
    else:
        self_test += f"   We should remember the word ____.\n"
        self_test += f"   A. {word}  B. test  C. example\n"
        self_test += f"   ç­”æ¡ˆï¼šA\n"
        self_test += f"   è§£æï¼šæ ¹æ®å¥å­æ„æ€ï¼Œè¿™é‡Œéœ€è¦å¡«å…¥{word}\n"
    
    self_test += "\n"
    
    # è¯­æ³•åˆ¤æ–­é¢˜
    self_test += "2. **è¯­æ³•åˆ¤æ–­**ï¼š\n"
    if word == "a" or word == "a/an":
        self_test += "   å¥å­'He is a student.'æ˜¯å¦æ­£ç¡®ï¼Ÿ\n"
        self_test += "   ç­”æ¡ˆï¼šæ­£ç¡®\n"
        self_test += "   è§£æï¼šstudentæ˜¯ä»¥è¾…éŸ³éŸ³ç´ å¼€å¤´çš„å•è¯ï¼Œæ‰€ä»¥ç”¨a\n"
    else:
        self_test += f"   å¥å­'I {word} this book.'æ˜¯å¦æ­£ç¡®ï¼Ÿ\n"
        self_test += "   ç­”æ¡ˆï¼šéœ€è¦æ ¹æ®å…·ä½“è¯­å¢ƒåˆ¤æ–­\n"
        self_test += "   è§£æï¼šå¦‚æœ{word}æ˜¯åŠç‰©åŠ¨è¯ï¼Œè¿™ä¸ªå¥å­ç»“æ„æ­£ç¡®\n"
    
    # è‰¾å®¾æµ©æ–¯å¤ä¹ æç¤º
    review_plan = "\n**è‰¾å®¾æµ©æ–¯å¤ä¹ æç¤º**ï¼š\n"
    review_plan += "- **ç¬¬1æ¬¡å¤ä¹ **ï¼šå­¦å®Œå½“å¤©ç¡å‰ï¼ˆ5åˆ†é’Ÿï¼‰\n"
    review_plan += f"  é‡ç‚¹çœ‹ï¼šå¿…è®°æ­é… + {word}çš„æ ¸å¿ƒå«ä¹‰\n"
    review_plan += "- **ç¬¬2æ¬¡å¤ä¹ **ï¼šç¬¬2å¤©æ—©ä¸Šï¼ˆ3åˆ†é’Ÿï¼‰\n"
    review_plan += f"  å¿«é€Ÿè¿‡ï¼š{word}çš„æ‹¼å†™ã€å‘éŸ³å’Œä¸»è¦ä¾‹å¥\n"
    review_plan += "- **ç¬¬3æ¬¡å¤ä¹ **ï¼šç¬¬7å¤©ï¼ˆ5åˆ†é’Ÿï¼‰\n"
    review_plan += f"  é‡åšè‡ªæµ‹é¢˜ï¼Œæ£€æŸ¥æ˜¯å¦çœŸæ­£æŒæ¡{word}\n"
    
    return f"### æ¨¡å—5ï¼šè‡ªæµ‹ä¸å¤ä¹ è§„åˆ’\n\n{self_test}{review_plan}\n"

def generate_personalized_interaction(word_info):
    """
    ç”Ÿæˆæ¨¡å—6ï¼šä¸ªæ€§åŒ–äº¤äº’ç¤ºä¾‹
    """
    word = word_info['word']
    
    # ç”¨æˆ·æé—®å“åº”ç¤ºä¾‹
    qa_examples = "**ç”¨æˆ·æé—®å“åº”ç¤ºä¾‹**ï¼š\n\n"
    qa_examples += f"1. **ç”¨æˆ·é—®**ï¼š'{word}é‡ç‚¹è€ƒä»€ä¹ˆï¼Ÿ'\n"
    qa_examples += f"   **å“åº”**ï¼š{word}åœ¨å­¦ä½è‹±è¯­è€ƒè¯•ä¸­ä¸»è¦è€ƒæŸ¥å…¶åŸºæœ¬å«ä¹‰å’Œç”¨æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨é˜…è¯»ç†è§£å’Œå®Œå½¢å¡«ç©ºä¸­çš„åº”ç”¨ã€‚å»ºè®®é‡ç‚¹æŒæ¡å…¶æ ¸å¿ƒå«ä¹‰ã€å¸¸è§æ­é…å’Œè¯­æ³•ç”¨æ³•ã€‚\n\n"
    
    qa_examples += f"2. **ç”¨æˆ·é—®**ï¼š'æ€ä¹ˆè®°{word}è¿™ä¸ªè¯ï¼Ÿ'\n"
    qa_examples += f"   **å“åº”**ï¼šæ¨èç»“åˆåœºæ™¯è®°å¿†æ³•ï¼Œå°†{word}æ”¾åœ¨å…·ä½“çš„å¥å­æˆ–åœºæ™¯ä¸­è®°å¿†ã€‚åŒæ—¶ï¼Œå¯ä»¥é€šè¿‡è”æƒ³è®°å¿†æ³•ï¼Œå°†{word}ä¸å·²å­¦è¿‡çš„ç›¸å…³è¯æ±‡è”ç³»èµ·æ¥è®°å¿†ã€‚\n\n"
    
    qa_examples += f"3. **ç”¨æˆ·é—®**ï¼š'å®Œå½¢å¡«ç©ºæ€ä¹ˆç”¨{word}ï¼Ÿ'\n"
    qa_examples += f"   **å“åº”**ï¼šåœ¨å®Œå½¢å¡«ç©ºä¸­ï¼Œä½¿ç”¨{word}æ—¶éœ€è¦æ³¨æ„å…¶å›ºå®šæ­é…å’Œè¯­æ³•ç”¨æ³•ã€‚ç»“åˆä¸Šä¸‹æ–‡è¯­å¢ƒï¼Œåˆ¤æ–­{word}åœ¨å¥å­ä¸­çš„è¯æ€§å’Œå«ä¹‰ï¼Œé€‰æ‹©æ­£ç¡®çš„å½¢å¼ã€‚\n"
    
    # è¿›åº¦é€‚é…ç¤ºä¾‹
    progress_examples = "\n**è¿›åº¦é€‚é…ç¤ºä¾‹**ï¼š\n\n"
    progress_examples += f"1. **ç”¨æˆ·æåŠ**ï¼š'å·²å­¦è¿‡ç›¸å…³è¯æ±‡'\n"
    progress_examples += f"   **å“åº”**ï¼šåœ¨å­¦ä¹ {word}æ—¶ï¼Œå¯ä»¥ä¸»åŠ¨å…³è”å·²å­¦è¿‡çš„ç›¸å…³è¯æ±‡ï¼Œå¯¹æ¯”å®ƒä»¬çš„åŒºåˆ«å’Œè”ç³»ï¼Œå¸®åŠ©æ›´å¥½åœ°ç†è§£å’Œè®°å¿†ã€‚\n\n"
    
    progress_examples += f"2. **ç”¨æˆ·æåŠ**ï¼š'å¤‡è€ƒå€’è®¡æ—¶'\n"
    progress_examples += f"   **å“åº”**ï¼šæ ¹æ®å¤‡è€ƒæ—¶é—´ï¼Œè°ƒæ•´å¤ä¹ è®¡åˆ’ï¼Œé‡ç‚¹èšç„¦{word}çš„é«˜é¢‘è€ƒç‚¹å’Œæ ¸å¿ƒç”¨æ³•ï¼Œæé«˜å­¦ä¹ æ•ˆç‡ã€‚\n"
    
    return f"### æ¨¡å—6ï¼šä¸ªæ€§åŒ–äº¤äº’ç¤ºä¾‹\n\n{qa_examples}{progress_examples}\n"

def generate_word_learning_materials(word_info):
    """
    ä¸ºå•ä¸ªå•è¯ç”Ÿæˆå®Œæ•´çš„å­¦ä¹ èµ„æ–™ï¼ŒæŒ‰ç…§æ¡ˆä¾‹ç¤ºèŒƒæ ¼å¼
    """
    word = word_info['word']
    
    materials = f"## è¯æ±‡å­¦ä¹ æ¡ˆä¾‹ï¼š{word}\n\n"
    materials += generate_vocabulary_basic_analysis(word_info)
    materials += generate_exam_focus(word_info)
    materials += generate_memory_strengthening(word_info)
    materials += generate_grammar_application(word_info)
    materials += generate_self_test_review(word_info)
    materials += generate_personalized_interaction(word_info)
    materials += "\n---\n\n"
    
    return materials

def generate_learning_record_table(words):
    """
    ç”Ÿæˆå­¦ä¹ è®°å½•è¡¨æ ¼
    """
    table = "## ğŸ“Š å­¦ä¹ è®°å½•è¡¨æ ¼\n\n"
    table += "| å•è¯ | æŒæ¡ç¨‹åº¦ | å­¦ä¹ æ—¥æœŸ | å¤ä¹ æ¬¡æ•° | å¤‡æ³¨ |\n"
    table += "|------|----------|----------|----------|------|\n"
    
    for word_info in words:
        table += f"| {word_info['word']} | â­â­â­ | | 0 | |\n"
    
    return table

def generate_summary(words, file_index, total_files):
    """
    ç”Ÿæˆå­¦ä¹ æ€»ç»“
    """
    total_words = len(words)
    summary = f"## ğŸ“ å­¦ä¹ æ€»ç»“\n\n"
    summary += f"- **æœ¬å•å…ƒå•è¯æ•°**ï¼š{total_words}ä¸ª\n"
    summary += f"- **å•å…ƒç¼–å·**ï¼šA{file_index+1}/{total_files}\n"
    summary += "- **å­¦ä¹ è¿›åº¦**ï¼š0%\n"
    summary += "- **å·²æŒæ¡å•è¯**ï¼š0ä¸ª\n"
    summary += "- **é‡ç‚¹å•è¯**ï¼šéœ€æ ¹æ®ä¸ªäººå­¦ä¹ æƒ…å†µæ ‡è®°\n"
    summary += "\n### ğŸ’ª å­¦ä¹ é¼“åŠ±\n"
    summary += "åšæŒæ¯å¤©å­¦ä¹ ï¼Œç›¸ä¿¡ä½ ä¸€å®šèƒ½å¤ŸæŒæ¡è¿™äº›å•è¯ï¼Œä¸ºå­¦ä½è‹±è¯­è€ƒè¯•æ‰“ä¸‹åšå®çš„åŸºç¡€ï¼"
    
    return summary

def main():
    """
    ä¸»å‡½æ•°
    """
    print("====== å¼€å§‹ç”ŸæˆAå­—æ¯å•è¯å­¦ä¹ èµ„æ–™ ======")
    
    # æå–Aå¼€å¤´çš„å•è¯
    a_words = extract_a_words(vocabulary_file)
    
    if not a_words:
        print("æœªæå–åˆ°ä»»ä½•Aå¼€å¤´çš„å•è¯ï¼Œæ— æ³•ç”Ÿæˆå­¦ä¹ èµ„æ–™")
        return
    
    # æ¯ä¸ªæ–‡ä»¶æ”¾50ä¸ªå•è¯ï¼Œè®¡ç®—éœ€è¦ç”Ÿæˆçš„æ–‡ä»¶æ•°é‡
    words_per_file = 50
    total_files = (len(a_words) + words_per_file - 1) // words_per_file
    
    # åˆ†æ–‡ä»¶ç”Ÿæˆå­¦ä¹ èµ„æ–™
    for i in range(total_files):
        start_idx = i * words_per_file
        end_idx = min((i + 1) * words_per_file, len(a_words))
        file_words = a_words[start_idx:end_idx]
        
        # ç”Ÿæˆå®Œæ•´çš„å­¦ä¹ èµ„æ–™
        full_materials = f"# Aå­—æ¯å•è¯å­¦ä¹ èµ„æ–™ - å•å…ƒ{i+1}\n\n"
        full_materials += "## ğŸ“– å­¦ä¹ è¯´æ˜\n\n"
        full_materials += "æœ¬èµ„æ–™æŒ‰ç…§å­¦ä½è‹±è¯­è¯æ±‡å­¦ä¹ æ¡ˆä¾‹ç¤ºèŒƒæ ¼å¼åˆ¶ä½œï¼ŒåŒ…å«å®Œæ•´çš„6ä¸ªå­¦ä¹ æ¨¡å—ã€‚\n"
        full_materials += "è¯·æŒ‰ç…§ä»¥ä¸‹æ–¹æ³•ä½¿ç”¨æœ¬èµ„æ–™ï¼š\n"
        full_materials += "1. æ¯å¤©å­¦ä¹ ä¸€å®šæ•°é‡çš„å•è¯\n"
        full_materials += "2. æ¯ä¸ªå•è¯éƒ½åŒ…å«è¯¦ç»†çš„ä¾‹å¥å’Œç”¨æ³•è¯´æ˜\n"
        full_materials += "3. å®Œæˆæ¯ä¸ªå•è¯çš„è‡ªæµ‹é¢˜\n"
        full_materials += "4. æŒ‰ç…§è‰¾å®¾æµ©æ–¯å¤ä¹ è®¡åˆ’å®šæœŸå¤ä¹ \n"
        full_materials += "5. åœ¨å­¦ä¹ è®°å½•è¡¨æ ¼ä¸­è®°å½•å­¦ä¹ æƒ…å†µ\n\n"
        
        # ä¸ºæ¯ä¸ªå•è¯ç”Ÿæˆå­¦ä¹ èµ„æ–™
        for parsed_word in file_words:
            full_materials += generate_word_learning_materials(parsed_word)
        
        # æ·»åŠ å­¦ä¹ è®°å½•è¡¨æ ¼
        full_materials += generate_learning_record_table(file_words)
        
        # æ·»åŠ å­¦ä¹ æ€»ç»“
        full_materials += generate_summary(file_words, i, total_files)
        
        # ä¿å­˜ç”Ÿæˆçš„å­¦ä¹ èµ„æ–™
        output_file = os.path.join(output_dir, f'Aå­—æ¯å•è¯å­¦ä¹ èµ„æ–™_å•å…ƒ{i+1}.md')
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(full_materials)
            print(f"å­¦ä¹ èµ„æ–™å·²æˆåŠŸç”Ÿæˆå¹¶ä¿å­˜è‡³ï¼š{output_file}")
            print(f"æ–‡ä»¶å…±åŒ…å« {len(file_words)} ä¸ªå•è¯")
        except Exception as e:
            print(f"ä¿å­˜å­¦ä¹ èµ„æ–™æ—¶å‡ºé”™: {e}")
    
    print("====== å¤„ç†å®Œæˆ ======")

if __name__ == "__main__":
    main()